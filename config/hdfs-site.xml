<?xml version='1.0'?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->
<configuration>
    <!-- These properties are generated by ClusterConsole automatically -->
    <property>
      <name>hadoop.tmp.dir</name>
      <value>/data/hadoop-tmp</value>
    </property>
    <property>
      <name>dfs.block.local-path-access.user</name>
      <value>hdfs</value>
    </property>
    <property>
      <name>dfs.replication</name>
      <value>1</value>
      <description>Number of times a block should be replicated in HDFS</description>
    </property>
    <!-- <property>
      <name>dfs.hosts</name>
      <value>/home/pradeepkumar/hbase-in-a-box/hbase.7/bigdata-hadoop/hadoop/hadoop/etc/hadoop/dfs-hosts.txt</value>
      <description>Whitelist of hosts in the cluster</description>
    </property>
    
    <property>
      <name>dfs.hosts.exclude</name>
      <value>/home/pradeepkumar/hbase-in-a-box/hbase.7/bigdata-hadoop/hadoop/hadoop/etc/hadoop/dfs-hosts-exclude.txt</value>
      <description>Hosts in the cluster that are not allowed to connect to Namenode</description>
    </property> -->    

    <!-- Namenode failover properties. These are only used if there is more than one namenode -->
    <!-- ZK quorum info for nn failover -->
    <property>
        <name>dfs.name.dir</name>
        <value>/data/hdfs</value>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>/data-1/hdfs,/data-2/hdfs</value>
    </property>
    <property>
        <name>dfs.permissions.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>0</value>
    </property>
    <property>
        <name>dfs.datanode.max.xcievers</name>
        <value>8192</value>
    </property>
    <property>
        <name>dfs.support.append</name>
        <value>true</value>
    </property>
    <property>
      <name>dfs.block.size</name>
      <value>134217728</value>
    </property>
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>1</value>
        <description>Allow two disks to fail before crashing the DN</description>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>64</value>
        <description>Number of server threads- defaults to 10</description>
    </property>
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>8</value>
        <description>Number of server threads- defaults to 3. Additional thread consumes more memory</description>
    </property>
    <!-- disable Nagle's -->
    <property>
        <name>ipc.server.tcpnodelay</name>
	<value>true</value>
    </property>
    <property>
        <name>ipc.client.tcpnodelay</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.datanode.synconclose</name>
        <value>true</value>
        <description>Sync each block to disk as it is closed. HDFS-1539</description>
    </property>
    <property>
        <name>dfs.datanode.sync.behind.writes</name>
        <value>true</value>
        <description>Best-effort sync changes. HDFS-2465</description>
    </property>

    <property>
        <name>dfs.namenode.avoid.read.stale.datanode</name>
        <value>true</value>
        <description>HDFS-3703/HDFS-4350 avoid DNs for reads if possible</description>
    </property>
    <property>
        <name>dfs.namenode.avoid.write.stale.datanode</name>
        <value>true</value>
        <description>HDFS-3912 avoid stale DNs for writes if possible</description>
    </property>

    <property>
        <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
        <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy</value>
        <description>HDFS-1804 hit drives with more space with higher probability for writes when free space is skewed (differs by more than 10GB by default)</description>
    </property>

    <!-- Standard HA Cluster properties.
    If these change, many of the above generates properties need to change too. -->
    <property>
        <name>dfs.nameservices</name>
        <value>master1</value>
        <description>A logical name for the name service - it doesn't necessarily need to be the same as the Name Service ID above.</description>
    </property>
</configuration>
